안녕하세요 자바라머신러닝입니다
이번 동영상은 타이타닉 생족분석을 weka 로 진행하면서
초급과정 복습과 Experimeter 에 의한 최적 모델제시 과정을 살펴보겠습니다

타이타닉 생존분석의 목적은
머신러닝 과정 중에서 알고리즘 선별과정을 습득하기 위해서입니다

특히 이번시간에 집중할 것은 대산선정과 단위설계의 중간단계입니다
물론 알고리즘이 선별되면 weka explorer에서 단위설계와
knwoledgeflow 를 통한 통합설계 그리고
java code 에 의한 시스템 체계화까지 진행합니다


간단하게 타이타닉 침몰사건을 요약해 보겠습니다 
100년도 넘은 1912년 대형유람선이 빙산에 충돌해서
4시간뒤에 침몰하면서 많은 사람이 사망한 대형해양 사고입니다

충돌하자 마자 바로 침몰하지 않았고 
구명보트 탑승여부가 생사의 갈림길을 결정했는데
기록을 보면 여자와 아이들을 먼저 보트에 탑승시키 되 
그중에 객실등급에 따라서 우선순위를 두었다고 합니다
그리고 침몰했는데요

여기서 우리가 알아야 할 점은 
성별과 객실등급이 생존에 큰 영향일 끼쳤음을 알 수 있습니다

데이터세트를 전처리할 때도 이점을 반영해야 합니다
즉 성별, 객실등급 독립변수는 어떤 경우라도 반드시 포함되어야 합니다

본격적인 과정에 들어가기에 앞서 
다른 머신러닝 언어들과 weka 를 비교해 보겠습니다

머신러닝을 이해하고 적용하기 위해 파이썬과 R 이 대중화 되어있습니다
이 2개 언어는 코딩으로 모든것을 구현하기 때문에 
프로그래밍을 알아야 한다는 선행조건이 있습니다
그리고 프로그래밍 개념을 안다고 해서 머신러닝을 모르면
어쩔 수 없이 시행착오를 겪어야만 합니다
그러나 시각화는 weka 보다 우수해서 관련자들과 소통하는데 용이합니다

weka 는 UI 를 통해서 머신러닝이 가능하기 때문에 
시행착오를 상대적으로 적게 격습니다
다만 시각화는 파이썬이나 R보다는 상대적으로 약하므로 
소통하는데 더 많은 노력이 필요합니다

타이타닉 생존분석 weka 머신러닝 과정을 살펴보겠습니다

타이타닉 생존 데이터를 확보하는 방법은
weka로 데이터세트를 불러올때
인터넷에서 arff 파일이나 csv 파일을 다운로드 받아오거나
인터넷의 url 을 사용해서 직접 불러오는 것입니다

전처리는 속성명 (독립변수) 와 데이터 일부를 한글로 변환하고
여러가지 상황에 맞는 데이터세트를 여러개 만듭니다

실험자는 상황에 맞개 만들어진 여러개 데이터세트에
8가지 정도의 알고리즘으로 비교를 하여
최적의 데이터세트와 알고리즘의 세트를 채택합니다

그러면 실제학습을
Knowledgeflow, Explorer, Java Code 순으로 진행합니다

weka 에서 데이터 획득방법은 4가지가 있습니다.
1) 저장되어 있는 파일을 불러오는 방법
2) 인터넷으로 공개되어 있는 arff 파일을 url로 불러오는 방법
3) database 에서 불러오는 방법
4) 임의로 generating 하는 방법입니다.

저장되어 있는 파일을 불러오는 방법은 앞으로도 많이 해볼테니
인터넷에 공개된 arff 파일을 url 로 불러와 보겠습니다.

그러면 url 을 알아야 하는데
먼저 titanic 데이터를 공개한 https://www.openml.org/d/40945 를 접속합니다
두번째로 url 을 크롬에서는 링크주소 복사 
또는 IE 에서는 속성에서 url 을 복사합니다.

만약 url 마지막에 .arff 라는 파일형식이 없으면 강제로 붙여주면 됩니다.

url 은 다음과 같습니다.

https://www.openml.org/data/download/16826755/phpMYEkMl.arff

그러면 weka explorer 에서 Open URL 을 클릭하고
url 을 붙여넣고 확인을 클릭합니다.

그러면 저장된 arff 파일을 불러오듯이
인터넷에 공개된 arff 파일을 불러옵니다

인터넷에 공개된 파일을 가져올때 조건이 있는데
1) arff 파일형태만 되고 2) 이 파일이 보안없이 공개된 경우일때 뿐입니다

전처리는 3가지로 진행됩니다.

arff 파일 내에 데이터타입이 String 으로 되어 있는
속성 (독립변수) 는 모두 nominal 형태로 변경합니다.

두번째 필터링을 통해 속성(독립변수)명이나 데이터 값을 한글로 변경하는데
사전에 확인해야 할 것이 weka charset 이 Cp949로 되어 있느냐 입니다.

속성명 (독립변수)를 변경하는 필터는 
unsupervised>attribute>RenameAttribute 이고,

데이터값을 변경하는 필터는 
unsupervised>attribute>RenameNominalValue 입니다.

세번째 전처리는 결측값과 이상값 처리인데 
결측값은 데이터 결측율이 33% 이상이면 수동으로 삭제하거나
unsupervised>attribute>ReplaceMissingValue 필터를 통해 
평균/모드로 대체합니다.

이상값의 경우 Visualize패널에서 유관식별후 해당데이터 수동삭제하는데
이번 실습에서는 제외합니다.

실험자 (Explerimenter)로 최적의 데이터세트와 알고리즘 세트를 선별합니다.
여러가지 데이터 세트를 Explorer 의 표준화 및 정규화 필터로 생성할 예정입니다
표준화와 정규화를 하면 좋다 안좋다 의견이 분분한데
표준화된 데이터세트와 정규화된 데이터세트를 Experimenter 로 비교해 보면 그만입니다

데이터 1309건 + 14개 속성으로 구성된 전체 데이터세트,
결측값 처리 (대체/삭제) 가 된 데이터세트
성별, 나이, 객실등급을 포함한 1309건 + 5~6개 속성의 데이터세트를 만듭니다.

그리고 보편적인 8 개 알고리즘 
rules.ZeroR/PART
bayes.NaiveBayes
functions.Logistic/SMO
lazy.IBk (knn = 3 변경)
trees.REPTree/trees.J48
을 사용합니다.

Experimenter 를 통해 실험을 하고 
최적 데이터세트와 알고리즘 선별 후 
Explorer 를 통한 단위설계
KnowledgeFlow 를 통한 통합설계
Java Code 를 통한 체계화를 진행합니다





































































































